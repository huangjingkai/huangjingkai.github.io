Kafka从首次发布之日起，已经走过了七个年头。从最开始的大规模消息系统，发展成为功能完善的分布式流式处理平台，用于发布和订阅、存储及实时地处理大规模流数据。来自世界各地的数千家公司在使用Kafka，包括三分之一的500强公司。Kafka以稳健的步伐向前迈进，首先加入了复制功能和无边界的键值数据存储，接着推出了用于集成外部存储系统的Connect API，后又推出了为实时应用和事件驱动应用提供原生流式处理能力的Streams API，并于今年春季开始支持仅一次处理语义。如此广泛的应用和完备的功能以及如此悠久的历史，无一不在说明Kafka已经成为一款稳定的企业级产品。而更为激动人心的是，Kafka现在正式迎来了1.0.0版本！

Kafka 1.0.0发布的主要内容如下。

0.10.0版本里开始引入的Streams API在1.0.0版本里继续演进，改进了builder API（KIP-120），新增了用于查看运行时活跃任务的API（KIP-130）和用于聚合分区的cogroup 
API（KIP-150）。增强的print()和writeAsText()方法让调试变得更容易（KIP-160）。其他更多信息可以参考Streams文档。
改进了Connect的度量指标（KIP-196），新增了大量用于健康监测的度量指标（KIP-188），并提供了集群的GloabalTopicCount和GlobalPartitionCount度量指标（KIP-168）。
支持Java 9，实现更快的TLS和CRC32C，加快了加密速度，降低了计算开销。
调整了SASL认证模块的错误处理逻辑（KIP-152），原先的认证错误信息现在被清晰地记录到日志当中。
更好地支持磁盘容错（KIP-112），更优雅地处理磁盘错误，单个JBOD上的磁盘错误不会导致整个集群崩溃。
0.11.0版本中引入的幂等性生产者需要将max.in.flight.requests.per.connection参数设置为1，这对吞吐量造成了一定的限制。而在1.0.0版本里，这个参数最大可以被设置为5（KAFKA-5949），极大提升了吞吐量范围。
关于新版本更多的变化可以查看发布说明，也可以下载源代码和二进制包（Scala 2.11、Scala 2.12）。
